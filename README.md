# Ollama Tools Chat - Chatbot with Ollama

This project implements an autonomous chat system using Ollama cappable of running LLMs with tools.

## ğŸ“‹ Description

The project allows creating a chat with MCP endpoint tools enabled.

## ğŸš€ Features

OpenAPI server support.
Raw tools support. (currently, requires editing source code)
     
## ğŸ›  Requirements

- Python 3.7+
- Ollama installed and running
- Required packages:
  - `ollama`
  - `aiss_ollama_chat`

## ğŸ“¦ Installation

1. Create a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   ```

2. Clone the repository:
   ```bash
   git clone <your-repository>
   cd ollamaChat
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Install package using:
   ```bash
   pip install .
   ```

## â–¶ï¸ Usage

Run the program with:
```bash
ollama-tools-chat <model> <prompt> <maxLength> <mcpServerAddress> <mcpServerPassword>
```

Example:
```bash
ollama-tools-chat gemma3:12b-it-q8_0 ./sysPrompt.txt 10 127.0.0.1:8100 password123
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ aiss_ollama_chat_autonomous/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat.py
â”‚   â””â”€â”€ run.py
â”œâ”€â”€ run.sh
â”œâ”€â”€ setup.py
â”œâ”€â”€ sysPrompt.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ“„ Output

Conversation history is saved in a timestamped folder:
```
Chat-A_2025-11-09_21-00-00/
â”œâ”€â”€ chat.log
â””â”€â”€ params.py
Chat-B_2025-11-09_21-00-00/
â”œâ”€â”€ chat.log
â””â”€â”€ params.py
```

## ğŸ¤ Contributions

Contributions are welcome! Please open an issue or submit a pull request.

## ğŸ“„ License

This project is licensed under the MIT License.